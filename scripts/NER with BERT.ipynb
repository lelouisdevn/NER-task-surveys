{"cells":[{"cell_type":"markdown","source":["# Install Transformers libraries "],"metadata":{"id":"9fPmc6xlD9zq"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"-7zXYXmXuWZa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682861896762,"user_tz":-420,"elapsed":36,"user":{"displayName":"Ngo Tran Vinh Thai B1910295","userId":"17537360154178872126"}},"outputId":"eda67442-2fc9-4949-cd90-f3ef8f737d5b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.12.0 dill-0.3.6 frozenlist-1.3.3 huggingface-hub-0.14.1 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 tokenizers-0.13.3 transformers-4.28.1 xxhash-3.2.0 yarl-1.9.2\n"]}],"source":["# Transformers installation\n","! pip install transformers datasets\n","# To install from source instead of the last release, comment the command above and uncomment the following one.\n","# ! pip install git+https://github.com/huggingface/transformers.git"]},{"cell_type":"markdown","metadata":{"id":"SI8-Syp1uWZn"},"source":["## Load PhoNER-COVID_19 dataset"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8mGbc4rnyXdG","executionInfo":{"status":"ok","timestamp":1682861920348,"user_tz":-420,"elapsed":23609,"user":{"displayName":"Ngo Tran Vinh Thai B1910295","userId":"17537360154178872126"}},"outputId":"f1d56346-450f-4ac5-ccfc-dbcf23840d7e"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["!pip install datasets"],"metadata":{"id":"lyU3ulBq1YMH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from datasets import Dataset"],"metadata":{"id":"QGUfO9Fy1bXt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json\n","import pandas as pd"],"metadata":{"id":"OCy0b1_-y_5g","executionInfo":{"status":"ok","timestamp":1682865219241,"user_tz":-420,"elapsed":433,"user":{"displayName":"Ngo Tran Vinh Thai B1910295","userId":"17537360154178872126"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["#Read training set \n","trainWord = [json.loads(line) for line in open('gdrive/MyDrive/Ct550/word/train_syllable.json', 'r', encoding='utf-8')]\n","trainWordData = pd.DataFrame(trainWord)\n","# trainWordData = trainWordData.rename(columns={'words':'source_text', 'tags':'target_text'})"],"metadata":{"id":"tSqfm9G1yqlY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainWordData"],"metadata":{"id":"0A_Phg5nz4Nv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset[0]"],"metadata":{"id":"HEB5atQU1gol"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6WeZFybLuWZn"},"source":["convert labels to ids with dictionary 'label2id'"]},{"cell_type":"code","source":["label2id = {\n","    \"O\":0,\n","    \"B-PATIENT_ID\":1,\n","    \"I-PATIENT_ID\": 2,\n","    \"B-NAME\":3,\n","    \"I-NAME\":4,\n","    \"B-AGE\":5,\n","    \"I-AGE\": 6,\n","    \"B-GENDER\":7,\n","    \"I-GENDER\":8,\n","    \"B-JOB\":9,\n","    \"I-JOB\":10,\n","    \"B-LOCATION\":11,\n","    \"I-LOCATION\":12,\n","    \"B-ORGANIZATION\":13,\n","    \"I-ORGANIZATION\":14,\n","    \"B-SYMPTOM_AND_DISEASE\":15,\n","    \"I-SYMPTOM_AND_DISEASE\":16,\n","    \"B-TRANSPORTATION\":17,\n","    \"I-TRANSPORTATION\":18,\n","    \"B-DATE\":19,\n","    \"I-DATE\":20\n","}"],"metadata":{"id":"lKK7duDF5F7f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels = []\n","for each in trainWordData['tags']:\n","  label = [label2id[entity] for entity in each]\n","  labels.append(label)"],"metadata":{"id":"G3X2dsYP5vKG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels[0]"],"metadata":{"id":"GrbhRf4S6YFo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["create an object and make it a dataset"],"metadata":{"id":"HuQgN04AER0C"}},{"cell_type":"code","source":["dict_obj = {'inputs':trainWordData['words'], 'labels':labels}\n","dataset = Dataset.from_dict(dict_obj)"],"metadata":{"id":"oLeUg8t96gcn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset[0]"],"metadata":{"id":"LHpVmhTV6jj5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681643948272,"user_tz":-420,"elapsed":530,"user":{"displayName":"Ngo Tran Vinh Thai B1910295","userId":"17537360154178872126"}},"outputId":"eaf6991f-033c-495a-caf0-b219e1dfa095"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'inputs': ['ƒê·ªìng',\n","  'th·ªùi',\n","  ',',\n","  'b·ªánh',\n","  'vi·ªán',\n","  'ti·∫øp',\n","  't·ª•c',\n","  'th·ª±c',\n","  'hi·ªán',\n","  'c√°c',\n","  'bi·ªán',\n","  'ph√°p',\n","  'ph√≤ng',\n","  'ch·ªëng',\n","  'd·ªãch',\n","  'b·ªánh',\n","  'COVID',\n","  '-',\n","  '19',\n","  'theo',\n","  'h∆∞·ªõng',\n","  'd·∫´n',\n","  'c·ªßa',\n","  'B·ªô',\n","  'Y',\n","  't·∫ø',\n","  '.'],\n"," 'labels': [0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  13,\n","  14,\n","  14,\n","  0]}"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["# load pretrained tokenizer"],"metadata":{"id":"pW3F8y0wEbnr"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"mfK20fhfuWZs"},"outputs":[],"source":["from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yX6GYCfvuWZs"},"outputs":[],"source":["example = wnut[\"train\"][0]\n","tokenized_input = tokenizer(example[\"tokens\"], is_split_into_words=True)\n","tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n","tokens"]},{"cell_type":"code","source":["example = dataset[0]\n","input_ids = tokenizer(example['inputs'], is_split_into_words=True)\n","tokens = tokenizer.convert_ids_to_tokens(input_ids['input_ids']) \n","tokens"],"metadata":{"id":"cIVd-_p70NP1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_qwALr4T6o4g","executionInfo":{"status":"ok","timestamp":1681643965078,"user_tz":-420,"elapsed":748,"user":{"displayName":"Ngo Tran Vinh Thai B1910295","userId":"17537360154178872126"}},"outputId":"d485c961-4d1c-43bb-aae1-9eed0947bee1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['inputs', 'labels'],\n","    num_rows: 5027\n","})"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["# handle mismatch betwwen words and labels"],"metadata":{"id":"P-3AjANZEq-H"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"MwVnwrr4uWZt"},"outputs":[],"source":["def tokenize_and_align_labels(examples):\n","    tokenized_inputs = tokenizer(examples[\"inputs\"], truncation=True, is_split_into_words=True)\n","\n","    labels = []\n","    for i, label in enumerate(examples['labels']):\n","        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n","        previous_word_idx = None\n","        label_ids = []\n","        for word_idx in word_ids:  # Set the special tokens to -100.\n","            if word_idx is None:\n","                label_ids.append(-100)\n","            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n","                label_ids.append(label[word_idx])\n","            else:\n","                label_ids.append(-100)\n","            previous_word_idx = word_idx\n","        labels.append(label_ids)\n","\n","    tokenized_inputs[\"labels\"] = labels\n","    return tokenized_inputs"]},{"cell_type":"markdown","metadata":{"id":"ZutBqOubuWZt"},"source":["# tokenize dataset with map method "]},{"cell_type":"code","source":["vt5_dataset = dataset.map(tokenize_and_align_labels, batched=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17,"referenced_widgets":["4563b4d7374e49f586d8c829d307fdac","4426f5762fe44feca369b607d6df5527","6216915656a74c15a72083d1076c73fe","28819aa9a2ad4b5dae5e53e8d154a8bf","48e5ecb2a7ed4192ac1e93ddb210324c","aaeb456a6a944d49a4f07faba96788d9","85366a998bf94cd1bdb757792fc0c2db","55af4305d44940df958b5ff5a7fd24ec","2d88b0146d7b4658a6e1cab8c37d4a9b","381e7f1684aa490c937a044a5060ede4","c57a559e7d5d40da99bca2f9fd7b444c"]},"id":"QLUejt4I19Px","executionInfo":{"status":"ok","timestamp":1681643975210,"user_tz":-420,"elapsed":1886,"user":{"displayName":"Ngo Tran Vinh Thai B1910295","userId":"17537360154178872126"}},"outputId":"7a1dbf37-0cbf-42bd-9bc9-db3c47fcd0b4"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/5027 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4563b4d7374e49f586d8c829d307fdac"}},"metadata":{}}]},{"cell_type":"code","source":["vt5_dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H4ybH2af6zhf","executionInfo":{"status":"ok","timestamp":1681643977855,"user_tz":-420,"elapsed":836,"user":{"displayName":"Ngo Tran Vinh Thai B1910295","userId":"17537360154178872126"}},"outputId":"784a29c8-933e-4d11-9d54-96c01eaa59f8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['inputs', 'labels', 'input_ids', 'attention_mask'],\n","    num_rows: 5027\n","})"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"NN2gWyrxuWZv"},"source":["Now create a batch of examples using [DataCollatorWithPadding](https://huggingface.co/docs/transformers/main/en/main_classes/data_collator#transformers.DataCollatorWithPadding). It's more efficient to *dynamically pad* the sentences to the longest length in a batch during collation, instead of padding the whole dataset to the maximum length."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OQsGW7hcuWZv"},"outputs":[],"source":["from transformers import DataCollatorForTokenClassification\n","\n","data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"]},{"cell_type":"markdown","metadata":{"id":"UthpV9liuWZv"},"source":["## Evaluate"]},{"cell_type":"markdown","metadata":{"id":"qOdE8ePBuWZv"},"source":["Including a metric during training is often helpful for evaluating your model's performance. You can quickly load a evaluation method with the ü§ó [Evaluate](https://huggingface.co/docs/evaluate/index) library. For this task, load the [seqeval](https://huggingface.co/spaces/evaluate-metric/seqeval) framework (see the ü§ó Evaluate [quick tour](https://huggingface.co/docs/evaluate/a_quick_tour) to learn more about how to load and compute a metric). Seqeval actually produces several scores: precision, recall, F1, and accuracy."]},{"cell_type":"code","source":["!pip install evaluate"],"metadata":{"id":"Mzo2OL0r6_96","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681718261344,"user_tz":-420,"elapsed":994,"user":{"displayName":"Ngo Tran Vinh Thai B1910295","userId":"17537360154178872126"}},"outputId":"593bbcb5-59c5-490c-f48a-b56f99178dd6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Installing collected packages: evaluate\n","Successfully installed evaluate-0.4.0\n"]}]},{"cell_type":"code","source":["!pip install seqeval"],"metadata":{"id":"CjzNgL_K7Y6u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681718273039,"user_tz":-420,"elapsed":5547,"user":{"displayName":"Ngo Tran Vinh Thai B1910295","userId":"17537360154178872126"}},"outputId":"8b78ecb3-dd49-4258-a105-85c67ff0eae2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=23adb2f7fb8731018cfc61aae453d8f4c87183c677f6d8b388c04f354dc90bf1\n","  Stored in directory: /root/.cache/pip/wheels/e2/a5/92/2c80d1928733611c2747a9820e1324a6835524d9411510c142\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vaK0-SlYuWZw","executionInfo":{"status":"ok","timestamp":1681718279536,"user_tz":-420,"elapsed":6541,"user":{"displayName":"Ngo Tran Vinh Thai B1910295","userId":"17537360154178872126"}},"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["b26f2f7e7cc44522b492955331f87fd1","b89977af0c314b4c826f8bee94ab397c","804e79f711bb489c909525ba36e7c80b","85c96ebba72c4bbd83d9eec456652ec9","dbcc335cd5db43409c75cc5e1583af11","7844a72cf51c4bedbde87e7569b67e3b","de4a5435e9724c019aadd12888f2b84b","6536311cf51c42d99ceaa64fd6dc34e9","35cee39875024a3ca5c84864d06c39b3","3ee0534e0c8849bc8430c3011ee1b5fe","11eaf4a18d7a4e99affe873c688f5704"]},"outputId":"287669ea-c599-45bc-95ca-20c59e794a04"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/6.34k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b26f2f7e7cc44522b492955331f87fd1"}},"metadata":{}}],"source":["import evaluate\n","\n","seqeval = evaluate.load(\"seqeval\")"]},{"cell_type":"markdown","metadata":{"id":"SBjhnKAKuWZw"},"source":["Get the NER labels first, and then create a function that passes your true predictions and true labels to [compute](https://huggingface.co/docs/evaluate/main/en/package_reference/main_classes#evaluate.EvaluationModule.compute) to calculate the scores:"]},{"cell_type":"code","source":["# labels = [label_list[i] for i in example[f\"ner_tags\"]]\n","# labels"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":252},"id":"Tywdvvy277U7","executionInfo":{"status":"error","timestamp":1681629635862,"user_tz":-420,"elapsed":343,"user":{"displayName":"Ng√¥ Tr·∫ßn Vƒ©nh Th√°i","userId":"17264747320111998544"}},"outputId":"de20b175-da3e-4d16-e81e-d061430b1ca5"},"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-92-0eec8ee22a80>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabel_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"ner_tags\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-92-0eec8ee22a80>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabel_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"ner_tags\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: 'Sequence' object is not subscriptable"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MD8dMTniuWZw"},"outputs":[],"source":["# import numpy as np\n","\n","# labels = [label_list[i] for i in example[f\"ner_tags\"]]\n","\n","\n","# def compute_metrics(p):\n","#     predictions, labels = p\n","#     predictions = np.argmax(predictions, axis=2)\n","\n","#     true_predictions = [\n","#         [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n","#         for prediction, label in zip(predictions, labels)\n","#     ]\n","#     true_labels = [\n","#         [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n","#         for prediction, label in zip(predictions, labels)\n","#     ]\n","\n","#     results = seqeval.compute(predictions=true_predictions, references=true_labels)\n","#     return {\n","#         \"precision\": results[\"overall_precision\"],\n","#         \"recall\": results[\"overall_recall\"],\n","#         \"f1\": results[\"overall_f1\"],\n","#         \"accuracy\": results[\"overall_accuracy\"],\n","#     }"]},{"cell_type":"markdown","metadata":{"id":"fZoW9RnouWZw"},"source":["Your `compute_metrics` function is ready to go now, and you'll return to it when you setup your training."]},{"cell_type":"markdown","metadata":{"id":"vNrbdMwduWZw"},"source":["## Train"]},{"cell_type":"markdown","metadata":{"id":"Y4MuhSYSuWZx"},"source":["Before you start training your model, create a map of the expected ids to their labels with `id2label` and `label2id`:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2L1IMjS6uWZx"},"outputs":[],"source":["id2label = {\n","    0: \"O\",\n","    1: \"B-PATIENT_ID\",\n","    2: \"I-PATIENT_ID\",\n","    3: \"B-NAME\",\n","    4: \"I-NAME\",\n","    5: \"B-AGE\",\n","    6: \"I-AGE\",\n","    7: \"B-GENDER\",\n","    8: \"I-GENDER\",\n","    9: \"B-JOB\",\n","    10: \"I-JOB\",\n","    11: \"B-LOCATION\",\n","    12: \"I-LOCATION\",\n","    13: \"B-ORGANIZATION\",\n","    14: \"I-ORGANIZATION\",\n","    15: \"B-SYMPTOM_AND_DISEASE\",\n","    16: \"I-SYMPTOM_AND_DISEASE\",\n","    17: \"B-TRANSPORTATION\",\n","    18: \"I-TRANSPORTATION\",\n","    19: \"B-DATE\",\n","    20: \"I-DATE\"\n","}\n","label2id = {\n","    \"O\":0,\n","    \"B-PATIENT_ID\":1,\n","    \"I-PATIENT_ID\": 2,\n","    \"B-NAME\":3,\n","    \"I-NAME\":4,\n","    \"B-AGE\":5,\n","    \"I-AGE\": 6,\n","    \"B-GENDER\":7,\n","    \"I-GENDER\":8,\n","    \"B-JOB\":9,\n","    \"I-JOB\":10,\n","    \"B-LOCATION\":11,\n","    \"I-LOCATION\":12,\n","    \"B-ORGANIZATION\":13,\n","    \"I-ORGANIZATION\":14,\n","    \"B-SYMPTOM_AND_DISEASE\":15,\n","    \"I-SYMPTOM_AND_DISEASE\":16,\n","    \"B-TRANSPORTATION\":17,\n","    \"I-TRANSPORTATION\":18,\n","    \"B-DATE\":19,\n","    \"I-DATE\":20\n","}"]},{"cell_type":"markdown","metadata":{"id":"nkk_VtYAuWZx"},"source":["<Tip>\n","\n","If you aren't familiar with finetuning a model with the [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer), take a look at the basic tutorial [here](https://huggingface.co/docs/transformers/main/en/tasks/../training#train-with-pytorch-trainer)!\n","\n","</Tip>\n","\n","You're ready to start training your model now! Load DistilBERT with [AutoModelForTokenClassification](https://huggingface.co/docs/transformers/main/en/model_doc/auto#transformers.AutoModelForTokenClassification) along with the number of expected labels, and the label mappings:"]},{"cell_type":"markdown","source":["# load BERT model"],"metadata":{"id":"kG-o6mwqE7Fk"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"lOFF2s3auWZx"},"outputs":[],"source":["from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n","\n","model = AutoModelForTokenClassification.from_pretrained(\n","    \"distilbert-base-uncased\", num_labels=21, id2label=id2label, label2id=label2id\n",")"]},{"cell_type":"code","source":["model.to('cuda')"],"metadata":{"id":"tXAhd1u_O5Kn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xa5RqKqWuWZx"},"source":["At this point, only three steps remain:\n","\n","1. Define your training hyperparameters in [TrainingArguments](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments). The only required parameter is `output_dir` which specifies where to save your model. You'll push this model to the Hub by setting `push_to_hub=True` (you need to be signed in to Hugging Face to upload your model). At the end of each epoch, the [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) will evaluate the seqeval scores and save the training checkpoint.\n","2. Pass the training arguments to [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) along with the model, dataset, tokenizer, data collator, and `compute_metrics` function.\n","3. Call [train()](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.train) to finetune your model."]},{"cell_type":"markdown","source":["# train model with 30 epochs,...."],"metadata":{"id":"kSZ14Bm_FDt5"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"WxhtQZd-uWZx","colab":{"base_uri":"https://localhost:8080/","height":747},"outputId":"96fde3de-4548-4fc4-ebd5-3c0dbcfb9b39","executionInfo":{"status":"ok","timestamp":1681645631921,"user_tz":-420,"elapsed":1593318,"user":{"displayName":"Ngo Tran Vinh Thai B1910295","userId":"17537360154178872126"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='9450' max='9450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [9450/9450 26:30, Epoch 30/30]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.406700</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.121900</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.068600</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.045000</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.030900</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.020400</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.015800</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.010200</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>0.008900</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.007700</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>0.005700</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>0.004700</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>0.003500</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>0.003300</td>\n","    </tr>\n","    <tr>\n","      <td>7500</td>\n","      <td>0.002900</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>0.002300</td>\n","    </tr>\n","    <tr>\n","      <td>8500</td>\n","      <td>0.002100</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>0.001700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=9450, training_loss=0.04042253855044249, metrics={'train_runtime': 1592.687, 'train_samples_per_second': 94.689, 'train_steps_per_second': 5.933, 'total_flos': 4347914296353786.0, 'train_loss': 0.04042253855044249, 'epoch': 30.0})"]},"metadata":{},"execution_count":25}],"source":["training_args = TrainingArguments(\n","    output_dir=\"gdrive/MyDrive/Ct550/checkpoints\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    num_train_epochs=30,\n","    weight_decay=0.01,\n","    # evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    # load_best_model_at_end=True,\n","    # push_to_hub=True,\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=vt5_dataset,\n","    # eval_dataset=tokenized_wnut[\"test\"],\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    # compute_metrics=compute_metrics,\n",")\n","\n","trainer.train()"]},{"cell_type":"markdown","metadata":{"id":"uf3awcx6uWZy"},"source":["## Inference"]},{"cell_type":"markdown","metadata":{"id":"CgnFGypPuWZy"},"source":["Great, now that you've finetuned a model, you can use it for inference!\n","\n","Grab some text you'd like to run inference on:"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"FL1X-OlmuWZy","executionInfo":{"status":"ok","timestamp":1682862104714,"user_tz":-420,"elapsed":706,"user":{"displayName":"Ngo Tran Vinh Thai B1910295","userId":"17537360154178872126"}}},"outputs":[],"source":["text = \"Ng√†y 15 / 3 , Vi·ªán Pasteur Th√†nh ph·ªë H·ªì Ch√≠ Minh v·ª´a c√¥ng b·ªë tr∆∞·ªùng h·ª£p b·ªánh nh√¢n 13 d∆∞∆°ng t√≠nh v·ªõi Covid - 19 , b·ªánh nh√¢n hi·ªán c√¥ng t√°c t·∫°i C·∫ßn Th∆° .\""]},{"cell_type":"markdown","metadata":{"id":"rCQvRBV1uWZy"},"source":["The simplest way to try out your finetuned model for inference is to use it in a [pipeline()](https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline). Instantiate a `pipeline` for NER with your model, and pass your text to it:"]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForTokenClassification\n","tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n","model = AutoModelForTokenClassification.from_pretrained(\"gdrive/MyDrive/Ct550/checkpoints/checkpoint-9450\")"],"metadata":{"id":"LfQ0Yn0C4-5Q","executionInfo":{"status":"ok","timestamp":1682862101666,"user_tz":-420,"elapsed":6,"user":{"displayName":"Ngo Tran Vinh Thai B1910295","userId":"17537360154178872126"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["model.to('cpu')"],"metadata":{"id":"MsTB7kpjW4nk"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M2UucLrQuWZz"},"outputs":[],"source":["from transformers import pipeline\n","\n","# classifier = pipeline(\"ner\", model=\"stevhliu/my_awesome_wnut_model\")\n","classifier = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n","classifier(text)"]},{"cell_type":"markdown","metadata":{"id":"6zIhGJKbuWZz"},"source":["You can also manually replicate the results of the `pipeline` if you'd like:\n","\n","Tokenize the text and return PyTorch tensors:"]},{"cell_type":"markdown","source":["# inference of a single example"],"metadata":{"id":"IWWUHRohFP_A"}},{"cell_type":"code","source":["import torch "],"metadata":{"id":"ogW02USoQPOf","executionInfo":{"status":"ok","timestamp":1682862136314,"user_tz":-420,"elapsed":582,"user":{"displayName":"Ngo Tran Vinh Thai B1910295","userId":"17537360154178872126"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def true_word_labels(tokens, labels): \n","  word_labels = []\n","  token_list = tokens[1:len(tokens)]\n","  label_list = labels[1:len(labels)]\n","\n","  j = 0\n","  for i in range(len(token_list)-1): \n","    ch = token_list[i][0:1]\n","    if ch == '#':\n","      j += 1\n","    elif ch == '/':\n","      if token_list[i+1].isdigit():\n","        j += 1\n","    elif ch.isdigit():\n","      if token_list[i-1] == '/' or token_list[i-1] == '.':\n","        j += 1\n","      else:\n","        word_labels.append(label_list[j])\n","        j += 1\n","    elif ch == '.' and token_list[i+1] != '[SEP]':\n","      j += 1\n","    else:\n","      word_labels.append(label_list[j])\n","      j += 1\n","  return word_labels"],"metadata":{"id":"mgc3MtAXBT1u"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4F7McGZ1uWZz"},"outputs":[],"source":["from transformers import AutoTokenizer\n","from transformers import AutoModelForTokenClassification\n","tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n","model = AutoModelForTokenClassification.from_pretrained(\"gdrive/MyDrive/Ct550/checkpoints/checkpoint-9450\")\n","# inputs = tokenizer(text, return_tensors=\"pt\")"]},{"cell_type":"code","source":["model.to('cuda')"],"metadata":{"id":"_zXMBoblOrY-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text = input(\"Sentence: \")\n","text = text.split()\n","inputs = tokenizer(text, return_tensors=\"pt\", is_split_into_words=True)\n","with torch.no_grad():\n","    logits = model(**inputs).logits\n","\n","predictions = torch.argmax(logits, dim=2)\n","predicted_token_class = [model.config.id2label[t.item()] for t in predictions[0]]"],"metadata":{"id":"Q8VZq6Sn597q","executionInfo":{"status":"ok","timestamp":1682862591894,"user_tz":-420,"elapsed":7590,"user":{"displayName":"Ngo Tran Vinh Thai B1910295","userId":"17537360154178872126"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f68c4166-a980-4cb0-abb0-41ddb5c0ebe2"},"execution_count":12,"outputs":[{"name":"stdout","output_type":"stream","text":["Sentence: Th√†nh ph·ªë C·∫ßn Th∆°\n"]}]},{"cell_type":"markdown","source":["# create a method which transforms tokens to words with their true labels"],"metadata":{"id":"qkhliiAIGDuy"}},{"cell_type":"code","source":["ids = inputs['input_ids'][0]\n","tokens = tokenizer.convert_ids_to_tokens(ids)\n","for i in range(len(ids)): \n","  print (tokens[i], \"-\", predicted_token_class[i])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"phhZKPTpmQmJ","executionInfo":{"status":"ok","timestamp":1682862594139,"user_tz":-420,"elapsed":6,"user":{"displayName":"Ngo Tran Vinh Thai B1910295","userId":"17537360154178872126"}},"outputId":"aad38cf5-414a-4316-89ad-eac93b1a77cb"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["[CLS] - O\n","than - B-LOCATION\n","##h - I-LOCATION\n","ph - I-LOCATION\n","##o - I-LOCATION\n","can - I-LOCATION\n","tho - I-LOCATION\n","[SEP] - I-NAME\n"]}]},{"cell_type":"code","source":["textt = ['Th√†nh', 'ph·ªë', 'C·∫ßn', 'Th∆°', 'l√†', 'th√†nh', 'ph·ªë', 'A']\n","labell = ['B-LOCATION', 'I-LOCATION', 'I-LOCATION', 'I-LOCATION', 'O', 'O', 'O', 'B-LOCATION']\n","\n","def toTokenLevel(text, label):\n","  n_labell = []\n","  for i in range(len(text)):\n","    tokenized_each = tokenizer(text[i]).input_ids\n","    real_tokens = tokenized_each[1:len(tokenized_each)-1]\n","    # print (real_tokens)\n","    tag = label[i][2:] #LOCATION\n","    \n","    for j in range(len(real_tokens)):\n","      if label[i][0:1] == 'B':\n","        if j == 0:\n","          n_labell.append('B-'+tag)\n","        else:\n","          n_labell.append('I-'+tag)\n","      else:\n","        n_labell.append(label[i])\n","  return n_labell"],"metadata":{"id":"-3iQ-m3EbicX","executionInfo":{"status":"ok","timestamp":1682865661032,"user_tz":-420,"elapsed":399,"user":{"displayName":"Ngo Tran Vinh Thai B1910295","userId":"17537360154178872126"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["print (toTokenLevel(textt, labell))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qQ7--aRRkH3_","executionInfo":{"status":"ok","timestamp":1682865663236,"user_tz":-420,"elapsed":9,"user":{"displayName":"Ngo Tran Vinh Thai B1910295","userId":"17537360154178872126"}},"outputId":"68550dea-8a91-44fa-e5b2-9febbb454f8f"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["['B-LOCATION', 'I-LOCATION', 'I-LOCATION', 'I-LOCATION', 'I-LOCATION', 'I-LOCATION', 'O', 'O', 'O', 'O', 'O', 'B-LOCATION']\n"]}]},{"cell_type":"code","source":["# print result with words and their labels\n","label = true_word_labels(tokens, predicted_token_class)\n","sentence = text\n","for i in range(len(sentence)):\n","  print (sentence[i], \"_\", label[i])\n","# printdata = {}\n","# printdata['sentence'] = sentence \n","# printdata['label'] = label \n","# pd.set_option('display.max_columns', 0)\n","# pd.DataFrame(printdata).T"],"metadata":{"id":"xMsno05nCFka","executionInfo":{"status":"error","timestamp":1681721101013,"user_tz":-420,"elapsed":506,"user":{"displayName":"Ngo Tran Vinh Thai B1910295","userId":"17537360154178872126"}},"colab":{"base_uri":"https://localhost:8080/","height":981},"outputId":"9037202f-bf18-42e1-8048-dcaad8cb6d76"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ƒê√¢y _ O\n","l√† _ O\n","c∆° _ O\n","s·ªü _ O\n","y _ O\n","t·∫ø _ O\n","th·ª© _ O\n","8 _ O\n","·ªü _ O\n","H√† _ B-LOCATION\n","N·ªôi _ I-LOCATION\n","ph·∫£i _ O\n","c√°ch _ O\n","ly _ O\n","s·ªë _ O\n","l∆∞·ª£ng _ O\n","l·ªõn _ O\n","nh√¢n _ O\n","vi√™n _ O\n","ho·∫∑c _ O\n","phong _ O\n","to·∫£ _ O\n","khu _ O\n","v·ª±c _ O\n","/ _ O\n","to√†n _ O\n","b·ªô _ O\n","b·ªánh _ O\n","vi·ªán _ O\n","sau _ O\n","khi _ O\n","ph√°t _ O\n","hi·ªán _ O\n","c√≥ _ O\n","b·ªánh _ O\n","nh√¢n _ O\n","ho·∫∑c _ O\n","c√≥ _ O\n","ti·∫øp _ O\n","x√∫c _ O\n","v·ªõi _ O\n","b·ªánh _ O\n","nh√¢n _ O\n"]},{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-104-270f1eeb0d13>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# printdata = {}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# printdata['sentence'] = sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"]}]},{"cell_type":"markdown","source":["# evaluation "],"metadata":{"id":"wpHr9GCCDehJ"}},{"cell_type":"markdown","source":["# first load devaluation dataset\n","\n"],"metadata":{"id":"Dmjzc_zFDgjW"}},{"cell_type":"code","source":["eval_dataset = [json.loads(line) for line in open('gdrive/MyDrive/Ct550/word/dev_syllable.json', 'r', encoding='utf-8')]\n","eval_dataset = pd.DataFrame(eval_dataset)"],"metadata":{"id":"rnzQgyjDNw2E","executionInfo":{"status":"ok","timestamp":1682865225530,"user_tz":-420,"elapsed":11,"user":{"displayName":"Ngo Tran Vinh Thai B1910295","userId":"17537360154178872126"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["word, tag"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oEjHotllmKJE","executionInfo":{"status":"ok","timestamp":1682865863443,"user_tz":-420,"elapsed":370,"user":{"displayName":"Ngo Tran Vinh Thai B1910295","userId":"17537360154178872126"}},"outputId":"01ec9205-ead1-402f-da76-abefd2a56e28"},"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(['B√°c',\n","  'sƒ©',\n","  'Nguy·ªÖn',\n","  'Trung',\n","  'Nguy√™n',\n","  ',',\n","  'Gi√°m',\n","  'ƒë·ªëc',\n","  'Trung',\n","  't√¢m',\n","  'Ch·ªëng',\n","  'ƒë·ªôc',\n","  ',',\n","  'B·ªánh',\n","  'vi·ªán',\n","  'B·∫°ch',\n","  'Mai',\n","  ',',\n","  'cho',\n","  'bi·∫øt',\n","  'b·ªánh',\n","  'nh√¢n',\n","  'ƒë∆∞·ª£c',\n","  'chuy·ªÉn',\n","  'ƒë·∫øn',\n","  'b·ªánh',\n","  'vi·ªán',\n","  'ng√†y',\n","  '7/3',\n","  ',',\n","  'ch·∫©n',\n","  'ƒëo√°n',\n","  'ng·ªô',\n","  'ƒë·ªôc',\n","  'thu·ªëc',\n","  'ƒëi·ªÅu',\n","  'tr·ªã',\n","  's·ªët',\n","  'r√©t',\n","  'chloroquine',\n","  '.'],\n"," ['O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'B-ORGANIZATION',\n","  'I-ORGANIZATION',\n","  'I-ORGANIZATION',\n","  'I-ORGANIZATION',\n","  'I-ORGANIZATION',\n","  'I-ORGANIZATION',\n","  'I-ORGANIZATION',\n","  'I-ORGANIZATION',\n","  'I-ORGANIZATION',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'B-DATE',\n","  'O',\n","  'O',\n","  'O',\n","  'B-SYMPTOM_AND_DISEASE',\n","  'I-SYMPTOM_AND_DISEASE',\n","  'I-SYMPTOM_AND_DISEASE',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O',\n","  'O'])"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","source":["word = eval_dataset['words'][0]\n","tag = eval_dataset['tags'][0]\n","new_word = tokenizer.convert_ids_to_tokens(tokenizer(word, is_split_into_words=True).input_ids)\n","new_tag = toTokenLevel(word, tag)\n","len(new_tag), len(new_word[1:-1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DUFnfJ2Jlbd-","executionInfo":{"status":"ok","timestamp":1682865794518,"user_tz":-420,"elapsed":423,"user":{"displayName":"Ngo Tran Vinh Thai B1910295","userId":"17537360154178872126"}},"outputId":"e95986b7-55ba-4011-aa53-c8a2e19bd218"},"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(73, 73)"]},"metadata":{},"execution_count":53}]},{"cell_type":"code","source":["input_texts = [' '.join(sentence) for sentence in eval_dataset['words']]"],"metadata":{"id":"UhubVXblOPRX","executionInfo":{"status":"ok","timestamp":1682865233366,"user_tz":-420,"elapsed":606,"user":{"displayName":"Ngo Tran Vinh Thai B1910295","userId":"17537360154178872126"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["input_texts[1024]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"CQb_95pRSjBM","executionInfo":{"status":"ok","timestamp":1682865235422,"user_tz":-420,"elapsed":15,"user":{"displayName":"Ngo Tran Vinh Thai B1910295","userId":"17537360154178872126"}},"outputId":"5eb0431f-524c-4afe-fad1-b8d801792fb7"},"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Tr∆∞·ªõc ƒë√≥ s√°ng 10 - 4 , √¥ng ƒêo√†n VƒÉn Tr·ªçng - ch·ªß t·ªãch UBND huy·ªán M√™ Linh , cho bi·∫øt sau khi ghi nh·∫≠n 5 ca COVID - 19 , huy·ªán M√™ Linh ƒë√£ r√† so√°t , ti·∫øn h√†nh c√°ch ly v·ªõi 411 tr∆∞·ªùng h·ª£p thu·ªôc di·ªán F1 , trong ƒë√≥ c√≥ 361 ng∆∞·ªùi ·ªü x√£ M√™ Linh , c√≤n l·∫°i ·ªü x√£ kh√°c ; ho√†n t·∫•t r√† so√°t v·ªõi 653 ng∆∞·ªùi ti·∫øp x√∫c thu·ªôc di·ªán F2 , ƒë√£ √°p d·ª•ng bi·ªán ph√°p c√°ch ly , theo d√µi s·ª©c kho·∫ª .'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":35}]},{"cell_type":"markdown","source":["# load 2000 sentence to produce predictions"],"metadata":{"id":"bwMC7cjeMaEx"}},{"cell_type":"code","source":["predicted_true_labels = []\n","for i in range(len(input_texts)):\n","  # print (i)\n","  texts = input_texts[i]\n","  inputs = tokenizer(texts, return_tensors='pt')\n","\n","  with torch.no_grad():\n","    logits = model(**inputs).logits\n","\n","  predictions = torch.argmax(logits, dim=2)\n","  predicted_token_class = [model.config.id2label[t.item()] for t in predictions[0]] \n","\n","  ids = inputs['input_ids'][0]\n","  tokens = tokenizer.convert_ids_to_tokens(ids) \n","  predicted_true_labels.append(true_word_labels(tokens, predicted_token_class)) "],"metadata":{"id":"F9O_fJlzO-Lb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# pd.DataFrame(predicted_true_labels)\n","len(predicted_true_labels)"],"metadata":{"id":"O66ewBzPQTf9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681718135286,"user_tz":-420,"elapsed":982,"user":{"displayName":"Ngo Tran Vinh Thai B1910295","userId":"17537360154178872126"}},"outputId":"79afa67a-3eab-4907-e125-e03dd114a46d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2000"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["references = [i for i in eval_dataset['tags']]"],"metadata":{"id":"_YeK704gROWn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["references"],"metadata":{"id":"BtdhWnK_RhTd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["count = 0\n","rlabels = []\n","ractual = []\n","error = []\n","for i in range(2000):\n","  if len(predicted_true_labels[i]) == len(references[i]):\n","    rlabels.append(predicted_true_labels[i]) \n","    ractual.append(references[i])\n","  # elif len(predicted_true_labels[i]) > len(references[i]):\n","  #   rlabels.append(predicted_true_labels[i][0:len(references[i])-1])\n","  #   ractual.append(references[i])\n","  #   print (len(predicted_true_labels[i]), len(references[i]))\n","  # else:\n","  #   error.append(input_texts[i])\n","  else:\n","    error.append(input_texts[i])"],"metadata":{"id":"zu-NsFUYR5Fx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(rlabels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OqPiUDFiVjZW","executionInfo":{"status":"ok","timestamp":1681719337355,"user_tz":-420,"elapsed":12,"user":{"displayName":"Ngo Tran Vinh Thai B1910295","userId":"17537360154178872126"}},"outputId":"db7226f1-60ad-411c-d608-65506ec13269"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1841"]},"metadata":{},"execution_count":68}]},{"cell_type":"code","source":["len(error)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VZG81Ha-2hwR","executionInfo":{"status":"ok","timestamp":1681719339334,"user_tz":-420,"elapsed":5,"user":{"displayName":"Ngo Tran Vinh Thai B1910295","userId":"17537360154178872126"}},"outputId":"144cfcc1-09a8-4a3c-90c4-11b8ee6a1d48"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["159"]},"metadata":{},"execution_count":69}]},{"cell_type":"code","source":["error"],"metadata":{"id":"tLVn_dgZVwTG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result = seqeval.compute(predictions=rlabels, references=ractual)\n","result"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-vEXBTa2PuJg","executionInfo":{"status":"ok","timestamp":1681719420001,"user_tz":-420,"elapsed":2079,"user":{"displayName":"Ngo Tran Vinh Thai B1910295","userId":"17537360154178872126"}},"outputId":"11677497-5e9b-43ac-fa5a-af5c25bf965a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'AGE': {'precision': 0.9898305084745763,\n","  'recall': 0.9668874172185431,\n","  'f1': 0.9782244556113904,\n","  'number': 302},\n"," 'DATE': {'precision': 0.9619771863117871,\n","  'recall': 0.9902152641878669,\n","  'f1': 0.9758919961427194,\n","  'number': 1022},\n"," 'GENDER': {'precision': 0.9672131147540983,\n","  'recall': 0.9711934156378601,\n","  'f1': 0.9691991786447639,\n","  'number': 243},\n"," 'JOB': {'precision': 0.7619047619047619,\n","  'recall': 0.6597938144329897,\n","  'f1': 0.707182320441989,\n","  'number': 97},\n"," 'LOCATION': {'precision': 0.8692185007974481,\n","  'recall': 0.896013152486642,\n","  'f1': 0.8824124671119207,\n","  'number': 2433},\n"," 'NAME': {'precision': 0.9032258064516129,\n","  'recall': 0.6363636363636364,\n","  'f1': 0.7466666666666666,\n","  'number': 88},\n"," 'ORGANIZATION': {'precision': 0.8020408163265306,\n","  'recall': 0.8103092783505155,\n","  'f1': 0.8061538461538462,\n","  'number': 485},\n"," 'PATIENT_ID': {'precision': 0.9728171334431631,\n","  'recall': 0.9907718120805369,\n","  'f1': 0.9817123857024107,\n","  'number': 1192},\n"," 'SYMPTOM_AND_DISEASE': {'precision': 0.7774687065368567,\n","  'recall': 0.8054755043227666,\n","  'f1': 0.7912243453644727,\n","  'number': 694},\n"," 'TRANSPORTATION': {'precision': 0.9746835443037974,\n","  'recall': 0.9625,\n","  'f1': 0.9685534591194969,\n","  'number': 80},\n"," 'overall_precision': 0.8966948273306655,\n"," 'overall_recall': 0.9116937914406269,\n"," 'overall_f1': 0.9041321078980797,\n"," 'overall_accuracy': 0.967977658831743}"]},"metadata":{},"execution_count":70}]},{"cell_type":"code","source":["# 1821 with the same length\n","result = seqeval.compute(predictions=rlabels, references=ractual)\n","result"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kumJIzoCRnlC","executionInfo":{"status":"ok","timestamp":1681718298151,"user_tz":-420,"elapsed":7904,"user":{"displayName":"Ngo Tran Vinh Thai B1910295","userId":"17537360154178872126"}},"outputId":"1652af99-1a91-41c9-a665-bb2077fc122f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'AGE': {'precision': 0.9898305084745763,\n","  'recall': 0.9668874172185431,\n","  'f1': 0.9782244556113904,\n","  'number': 302},\n"," 'DATE': {'precision': 0.9619771863117871,\n","  'recall': 0.9902152641878669,\n","  'f1': 0.9758919961427194,\n","  'number': 1022},\n"," 'GENDER': {'precision': 0.9672131147540983,\n","  'recall': 0.9711934156378601,\n","  'f1': 0.9691991786447639,\n","  'number': 243},\n"," 'JOB': {'precision': 0.7619047619047619,\n","  'recall': 0.6597938144329897,\n","  'f1': 0.707182320441989,\n","  'number': 97},\n"," 'LOCATION': {'precision': 0.8692185007974481,\n","  'recall': 0.896013152486642,\n","  'f1': 0.8824124671119207,\n","  'number': 2433},\n"," 'NAME': {'precision': 0.9032258064516129,\n","  'recall': 0.6363636363636364,\n","  'f1': 0.7466666666666666,\n","  'number': 88},\n"," 'ORGANIZATION': {'precision': 0.8020408163265306,\n","  'recall': 0.8103092783505155,\n","  'f1': 0.8061538461538462,\n","  'number': 485},\n"," 'PATIENT_ID': {'precision': 0.9728171334431631,\n","  'recall': 0.9907718120805369,\n","  'f1': 0.9817123857024107,\n","  'number': 1192},\n"," 'SYMPTOM_AND_DISEASE': {'precision': 0.7774687065368567,\n","  'recall': 0.8054755043227666,\n","  'f1': 0.7912243453644727,\n","  'number': 694},\n"," 'TRANSPORTATION': {'precision': 0.9746835443037974,\n","  'recall': 0.9625,\n","  'f1': 0.9685534591194969,\n","  'number': 80},\n"," 'overall_precision': 0.8966948273306655,\n"," 'overall_recall': 0.9116937914406269,\n"," 'overall_f1': 0.9041321078980797,\n"," 'overall_accuracy': 0.967977658831743}"]},"metadata":{},"execution_count":33}]},{"cell_type":"markdown","source":["# tokenize evaldataset to token level and their labels for token level prediction "],"metadata":{"id":"6ZoiD14yZucN"}},{"cell_type":"code","source":["eval_dataset['words'][0]"],"metadata":{"id":"Ri5zR0OBZ7Hz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labelsss = []\n","j = 0\n","for i in range(len(eval_dataset['words'][0])):\n","  word = eval_dataset['words'][0][i]\n","  ids = tokenizer(word).input_ids\n","  token = tokenizer.convert_ids_to_tokens(ids)\n","  token = token[1:len(token)-1]\n","  print (token)\n","\n","  first_word = 0\n","  for i in range(len(token)):\n","    if first_word == 0:\n","      labelsss.append(eval_dataset['tags'][0][i])\n","      first_word += 1\n","    else:\n","      abc = eval_dataset['tags'][0][i]\n","      abc = abc[2:]\n","      labelsss.append(\"I-\".join(abc))\n","  j += 1"],"metadata":{"id":"YUJoRDrAaCo7"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/huggingface/notebooks/blob/main/transformers_doc/en/pytorch/token_classification.ipynb","timestamp":1681626846162}]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"},"gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"4563b4d7374e49f586d8c829d307fdac":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4426f5762fe44feca369b607d6df5527","IPY_MODEL_6216915656a74c15a72083d1076c73fe","IPY_MODEL_28819aa9a2ad4b5dae5e53e8d154a8bf"],"layout":"IPY_MODEL_48e5ecb2a7ed4192ac1e93ddb210324c"}},"4426f5762fe44feca369b607d6df5527":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aaeb456a6a944d49a4f07faba96788d9","placeholder":"‚Äã","style":"IPY_MODEL_85366a998bf94cd1bdb757792fc0c2db","value":"Map:  99%"}},"6216915656a74c15a72083d1076c73fe":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_55af4305d44940df958b5ff5a7fd24ec","max":5027,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2d88b0146d7b4658a6e1cab8c37d4a9b","value":5027}},"28819aa9a2ad4b5dae5e53e8d154a8bf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_381e7f1684aa490c937a044a5060ede4","placeholder":"‚Äã","style":"IPY_MODEL_c57a559e7d5d40da99bca2f9fd7b444c","value":" 5000/5027 [00:01&lt;00:00, 3307.32 examples/s]"}},"48e5ecb2a7ed4192ac1e93ddb210324c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"aaeb456a6a944d49a4f07faba96788d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85366a998bf94cd1bdb757792fc0c2db":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"55af4305d44940df958b5ff5a7fd24ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d88b0146d7b4658a6e1cab8c37d4a9b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"381e7f1684aa490c937a044a5060ede4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c57a559e7d5d40da99bca2f9fd7b444c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b26f2f7e7cc44522b492955331f87fd1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b89977af0c314b4c826f8bee94ab397c","IPY_MODEL_804e79f711bb489c909525ba36e7c80b","IPY_MODEL_85c96ebba72c4bbd83d9eec456652ec9"],"layout":"IPY_MODEL_dbcc335cd5db43409c75cc5e1583af11"}},"b89977af0c314b4c826f8bee94ab397c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7844a72cf51c4bedbde87e7569b67e3b","placeholder":"‚Äã","style":"IPY_MODEL_de4a5435e9724c019aadd12888f2b84b","value":"Downloading builder script: 100%"}},"804e79f711bb489c909525ba36e7c80b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6536311cf51c42d99ceaa64fd6dc34e9","max":6338,"min":0,"orientation":"horizontal","style":"IPY_MODEL_35cee39875024a3ca5c84864d06c39b3","value":6338}},"85c96ebba72c4bbd83d9eec456652ec9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ee0534e0c8849bc8430c3011ee1b5fe","placeholder":"‚Äã","style":"IPY_MODEL_11eaf4a18d7a4e99affe873c688f5704","value":" 6.34k/6.34k [00:00&lt;00:00, 154kB/s]"}},"dbcc335cd5db43409c75cc5e1583af11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7844a72cf51c4bedbde87e7569b67e3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de4a5435e9724c019aadd12888f2b84b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6536311cf51c42d99ceaa64fd6dc34e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35cee39875024a3ca5c84864d06c39b3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3ee0534e0c8849bc8430c3011ee1b5fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11eaf4a18d7a4e99affe873c688f5704":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}